<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<script type="text/javascript" src="https://kanasimi.github.io/CeJS/ce.js">//{"run":"../resources/reviews.js"}</script>
<title>被操弄的真實：演算法中隱藏的政治與權力</title>
</head>
<body>
<h1><a href="https://colorlessecho.github.io/reviews/">讀書劄記 @ Colorless echo -the days never back-</a></h1>
<a id="If...Then"></a><div id="c_If...Then" class="c2" title="被操弄的真實：演算法中隱藏的政治與權力">
<h2><a rel="nofollow" href="https://www.books.com.tw/products/0010883897" accessdate="2022/6/28" title="博客來-被操弄的真實：演算法中隱藏的政治與權力">被操弄的真實：演算法中隱藏的政治與權力</a></h2>
前兩本又是詳細記錄書中論點，讀書筆記又臭又長。這本又想說別再那麼費工了，要不然一本書都得看上好幾個月。所以預定只紀錄特別的感觸。<br />
<a rel="nofollow" class="proper_noun" href="http://tainabucher.com/" accessdate="2022/6/29">Taina Bucher</a> 這本 <span class="creation_title" lang="en-US">If...Then: Algorithmic Power and Politics</span> 用字遣詞頗有學究氣息。說難聽點，文謅謅的需要大腦多轉幾圈。許多句子還附上論文格式的參照來源。事實上其中許多章節都是學術文章改編<span class="page">13–14</span>。
<div class="timeStamp">2022/6/23</div>


<h2>一、緒論：經過程式設計的社會性</h2>
這本書談的題材有點像 <a>Weapons of Math Destruction</a>，都在解說許多人尚未正視的演算法可能如何影響媒體並出問題<span class="page">40</span>。<br />
當前世界，每天上社交軟體是許多人的日常<span class="page">22</span>。每次社交媒體斷線都會造成許多人哀嚎。人們生活少不了它們，甚至獲取資訊的管道也受其把持。不僅社交平臺，現代許多組織機構都依賴演算法來做決策<span class="page">20–21</span>，其背後的算法因之掌控了左右人類生活的政治權利。<br />
演算法的初衷當然是良善的，並且也極力接近真實。舉例來說，無論愛情友情等等感情，都奠基於過去共同經歷的回憶<span class="page">23</span>，是需要花費時間培養的社會關係<span class="page">28</span>。Facebook 極力探索人與人的連結，並挖掘出對用戶可能有價值的<span class="page">26</span>。理想情況下，演算法只是強化了人的效率，就算沒這些算法，我們也希望這麼做<span class="page">55</span><span class="explanatory">（<a>Homo Deus</a> <span class="creation_title">第11章 信數據得永生？</span>）</span>。演算法會犯的錯誤，大多是由人類來做也會犯的。問題是編寫與採用演算法的人，其目的可能與接受演算法的用戶相悖，這時就會產生人們不樂意見到的麻煩。更糟糕的是，有時因交互作用複雜，演算法還會產生連編寫者都不預期的副作用，後果比傳統決策工具更難預見。好比說若太在乎讚的數量，以及瀏覽數，反而可能使我們陷入焦躁，與從交友關係感受愉悅幸福的初衷背道而馳<span class="page">34</span>。尤其當某些演算法應用範圍過大，這些困擾更加明顯。
<p>
如今社群平臺經營目的往往是為了<b>擴展客源與黏著度</b>，最終以<b>能投放多少廣告並賺錢</b>來衡量一個人<span class="page">33, 36</span><span class="explanatory">（<a>21 Lessons for the 21st Century</a> <span class="creation_title">第5堂課 社群：要認清「人類還有身體」</span>）</span>，非站在用戶的立場，或讓世界變好。所以平臺要求用戶多填寫個人履歷、分析與他人的互動（每一次點擊）以增加可利用的資訊<span class="page">35</span>。如同遊戲般想辦法利用人性弱點，讓用戶陷入其中不可自拔。演算法盡可能讓用戶與特定使用者營造共同回憶，培養感情，主要目的卻不是鞏固對用戶來說最值得持續下去、用戶最終將認同的友情。遑論依照實際比例來展示世界的真相給用戶們<span class="page">24, 26</span><span class="explanatory">（<a>Prius or Pickup?</a> <span class="creation_title">有線新聞、社群與網站之偏頗消息煽風點火</span>）</span>。從某個角度說來，這些關係是被製造出來的。沒有社群平臺，你不會知道這些人、與他們深入交往，更不會那麼勤奮的營造和他們的關係，包括但不限於生日問候、分享快樂、關懷低潮友人。另一方面，有些人或許本來會成為好朋友，但在社群媒體運作下，終至形同陌路。<br />
當演算法可大幅干預用戶生活圈的情況下，何謂朋友也從傳統的社交關係，轉成了演算法的自定義<span class="page">30</span>。Facebook 的算法對許多用戶來說，決定了該展示誰的消息，控制著朋友的親密度<span class="page">27</span>。在 Facebook 平臺上，人甚至能跟一首歌、一部電影「交朋友」<span class="page">29–30</span>。當 Facebook 封鎖某些人時，他們在網路上形同銷聲匿跡隱形人。不但如此，由於 Facebook 的重大影響力，這種封鎖還會損害被封鎖者的現實生活。雖然演算法不能和傳統定義差距過大，但確實徐徐干擾著社會的演進。
</p>
我想演算法的權力其實是我們人類賦予的。當經營者採用特定演算法，使用者願意加入此平臺，我們就賦予了此算法左右我們生活的權利<span class="page">20</span>。但是當平臺或演算法規模過大、過於權威，例如成為行業標准或者受有力機構與政府採用，一般人不得不利用它們、接納其安排時，就失去了自由選擇與參與的權利，只能被動接受<span class="explanatory">（<a>World Without Mind</a> <span class="creation_title">前言</span>）</span>。我覺得這類情況，證照制度、入學考試差可比擬。如同我們交朋友原先不需要經過社交平臺、人與人溝通無需即時通訊軟體如 LINE，人的能力也不見得非得考個證照或經過入學考試才能證明。但是當社會機構普遍採用證照、進學校須入學考，人們也大多接受時，沒考試的人反而會被怪罪為何不去試試。這時權力是由採用機構，以及所接納的大眾（社會共識）所賦予；不願接受的人，嚴重的話甚至只有退出社群這個選擇。對權威措施有異議者，頂多只能依靠更基本的公平正義原則，來質疑這些機制的可信度、是否符合其宣稱的目的，以及其存在必要性。就算最後討回公道，往往也是遲來的正義。更大的問題是，有時權威機構領導者採用了某個機制，其他人僅能被迫接受。這時或許可謂這些權勢者竊取了公眾權利，未經公眾討論就直接將改變結果當成大家願意接受的社會共識。所以這些權威機構所做的決策，不可說完全屬於自己的權利範圍、只要為股東負責就好，更不能說<del>不爽不要做</del>不滿意就別用、太平洋沒加蓋，因為其效果會外溢，有些人不願意卻別無選擇。任何決策皆應經過所有受影響者討論方可實施<span class="explanatory">（<a>The Tyranny of Merit</a> <span class="creation_title">第二章 「良善故偉大」：才德思想簡史</span>）</span>。
<div class="timeStamp">2022/6/29</div>


<h2>二、演算法的多樣性</h2>
談到演算法時，不同人指涉的其實是不同的意涵，這使演算法這一詞有著許多不同定義<span class="page">48–49</span>。比起將之視為單體、企圖精確定義「演算法」這個詞，不如承認其多樣性、探討演算法的效用與影響<span class="page">84, 115</span>。<br />
我想演算法是一組處理程序，處理所有可用資料，且獲得使用者所預期的結果<span class="page">52–53, 277</span>。既然演算法只是由人類所制定或審核，用來代替人、提高人工效率的工具，自然也包含政治意涵<span class="page">55</span>，內含人與文明的偏見，不該只當作數學公式看待。像是哪些人拿何種演算法來解決什麼問題之類，使用時機也很重要。<br />
有時演算法像法律一樣具備潛移默化的效用，能引導公眾的價值觀、定義對錯好壞。例如<a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E6%96%87%E7%AB%A0%E7%9B%B8%E4%BC%BC%E5%BA%A6%E6%AA%A2%E6%B8%AC" accessdate="2022/7/14" title="plagiarism detection, content similarity detection">文章相似度檢測</a>軟體能決定何謂抄襲，可讓作者同意被偵測出來的就是壞論文<span class="page">81</span>，社群媒體能使用戶堅信熱門文章就是好文章。<br />
由於這些工具只是處理事情的手段之一，我們不該只提供特定手段而忽視例外；必須附加包括積極收集受影響者意見的評鑑反饋方法，並且從錯誤中學習、改正，尤其針對設計當初未納入所有受影響者思慮產生的疏失。例如設計 ATM 的人可能就沒考慮到盲人和身體障礙人士，因此必須提供補救辦法<span class="page">77</span>。對於<a rel="nofollow" href="https://news.ltn.com.tw/news/world/breakingnews/3661590" accessdate="2022/7/13" title="將黑人標注為「靈長類動物」 臉書 AI 功能出包急道歉 - 國際 - 自由時報電子報">圖片辨識錯誤</a><span class="page">78–79</span>，則需要檢核演算法的運作機制並且適當修正。不過如之前所述，由於現在的演算法大多採用黑箱的機器學習法，沒有解釋行為的能力（非<a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E5%8F%AF%E8%A7%A3%E9%87%8B%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7" accessdate="2020/10/30" title="explainable AI, XAI">可解釋人工智慧</a>）；你問機器為何要這麼做，它也說不出個所以然來，遑論要細部改善。這類型修正還有賴演算法設計者改進<span class="explanatory">（<a>Reading Minds</a> <span class="creation_title">第五章 心智理論的理論特性</span>）</span>。
<p>
本章節在討論演算法的權力時，提到權力是社會存在的先決條件<span class="page">74</span>。我想其原因是一個人會選擇加入社群，主要在於有無社群對個人具差別，身在此社群中能帶給他好處。假如整體說來自己一個人過更好，就不會選擇加入了。社群與個人的差異在團體中人與人相依、相互影響。由於團體共識可規範成員，在遇到威脅時便可靠著團結獲得更大的力量。當然這種團結作用的範圍有限，例如中國再如何「團結」也很難輕易造出光刻機、量產尖端晶片；因為<q>團結力量大</q>多只針對蠻力、可從<a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E8%85%A6%E5%8A%9B%E6%BF%80%E7%9B%AA%E6%B3%95" accessdate="2016/4/17" title="腦力激盪法（英語：brainstorming），又稱為頭腦風暴法">腦力激盪</a>迅速獲得的成果，而非複雜知識技能。<br />
通常成員能受團體保護，並且取得社群成員特有的福利。例如當前受制裁的中國公司或者個人，就不能使用美國公司的技術與產品。所謂權力就是左右他人行為以至思想的能力<span class="explanatory">（<a>La vie est à nous</a> <span class="creation_title">權力</span>）</span>，也就是這種團體規範成員的力量，因此說權力先於社會存在。不想受權力影響，有時只能選擇完全退出社群，而其後果甚至會受懲罰以致追殺；因為有時成員已經獲得好處，就不好說想走就走，必須先回報與所獲得好處相當的貢獻。然而就社群的立場來說，放走這個人可能對社群威脅甚大、使社群處於不利地位，或者有些貢獻甚至必須以生命償還（例如熟知核心技術），這時就很難放人了。
</p>
<div class="timeStamp">2022/7/16</div>


<h2>三、既不黑，也不是箱子：理解或不去理解演算法</h2>
<a rel="nofollow" href="https://en.wikipedia.org/wiki/Transparency_(behavior)" accessdate="2018/7/10" title="transparency">透明度</a>本身不是目標，卻是我們討論事情的先決條件<span class="page">89</span>。除了非<a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E5%8F%AF%E8%A7%A3%E9%87%8B%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7" accessdate="2020/10/30" title="explainable AI, XAI">可解釋人工智慧</a>造成的黑箱<span class="page">250, 301, 304</span><span class="explanatory">（<a>Physics of the Future</a> <span class="creation_title">第二章：人工智能的未來——機器的興起</span>、<a>Life 3.0</a> <span class="creation_title">第2章 東西變聰明了</span>）</span>——這是連內部技術人員自己都無法解決的問題——外，現在更有許多藉著個人隱私、商業機密或國家安全與軍事機密之名而創造出來的黑箱<span class="page">94–96</span><span class="explanatory">（<a>WTF</a> <span class="creation_title">第9章 火熱的性子遇上冰冷的法令</span>）</span>。許多問題想解決首先遇到的困難，都是資訊不足、運作過程不夠透明，所以我們爭論半天終究是言不及義打高空。這些隱藏的秘密就算不公開，最少也該經由第三方公正機構檢核<span class="page">96</span>。將演算法說成黑箱，會削弱透明化演算法的動機與力度，出事時並可以此推卸責任<span class="page">116–117</span>。<br />
關於 Bucher 提到，太過透明卻可能干擾我們的視野，造成我們忽略要從某些角度來討論事情<span class="page">97</span>。我覺得這是視角與篩選的問題：我們必須從整體來檢核演算法，卻也必須從內部解析。為研究演算法原理之外、於社會互動間產生的的副作用<span class="page">296</span>，光研究原始碼還不夠<span class="page">218</span>；但有能力解析原始碼的話不應捨本逐末，放棄探究算法原理。資訊雜亂就必須經過篩選排序才知道有哪些特殊之處<span class="explanatory">（<a>The Inevitable</a> <span class="creation_title">7. FILTERING 篩選統整</span>）</span>，複雜絕對不是我們可以為黑箱辯護的理由。因此我們還是得盡可能透明化、多掌握所討論議題的相關資訊。
<p>
能夠從演算法的原理來判斷問題到底出在哪當然很好，畢竟演算法都是人工創造出來的，不該有搞不清楚問題出在哪邊的情況。就算向來被稱為黑箱的<a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C" accessdate="2016/3/13" title="ANNs 類神經網絡 artificial neural network">人工神經網路</a>，研究者也會努力調控演算結果、使其盡可能符合預期，要不然就不會端出來了。理想情況下，再不濟亦須加上補救措施，並<b>將所有資訊公開給所有受影響者</b>。遺憾的是在這不公開又不透明的世界，人們的觀念與社會制度尚未完備，想做到這點不容易，這時我們只好曲線救國。<br />
想當初人類面對自然界，可非對所有現像背後的運作原理都知根知底。黑箱才是常態<span class="page">121–122</span>，但這不妨礙人類探索世界的企圖心。我們靠著研究事物的關聯性與因果關係，導出了物理學、化學等各種自然科學，以及心理學、政治法律、歷史地理等社會科學。同樣的，當無法深入演算法本身時，我們依舊能退一步從其影響推導原理。對於演算法我們最起碼也該如此研究，包括理解其功能、作用範圍（哪些人受影響）、與環境如何互動、何時何地發生作用、由誰為了何種目的採用等<span class="page">124, 129</span>。當然我們必須知曉<b>這是不理想的情況</b>，有可能的話最好從演算法內部運作機制著手，這樣會更有效率也更完備；不是以「黑箱」輕輕放過，好像我們所有的手段就只能採反向工程<span class="page">123</span>。<br />
此外無論我們是不是了解演算法，都必須觀察其與環境的交互作用（包括從整體的角度<span class="page">128</span>）、是否發生非預期的副作用（如外溢效應、對演算法的不當利用）<span class="page">126–127</span>、若有問題應解決。部分演算法（如線上功能）會不斷改變演進<span class="page">100–102</span>，這種觀察也必須常時持續，甚至延伸到停止採用演算法後有何後遺症。對於人類支配下的演算法，我們得使這些工具符合理想，而非任由不良演算法肆虐。

</p>
有些情況我們希望採用演算法，有時則希望由人類來判定。Bucher 舉了個例：2016年 Facebook <span title="Trending Topic">趨勢話題</span><a rel="nofollow" href="https://www.nytimes.com/2016/05/13/technology/facebook-guidelines-trending-topics.html" accessdate="2022/7/27" title="Facebook, Facing Bias Claims, Shows How Editors and Algorithms Guide News - The New York Times">依賴於一個有偏見的人工編輯團隊</a>，和他們所宣稱採用演算法公正的決定不同，因此被罵翻。（後來<a rel="nofollow" href="https://technews.tw/2016/08/31/facebooks-trending-topics-algorithm-already-screwed-up/" accessdate="2022/7/27" title="撤掉人工編輯不到 3 天，完全靠演算法的 Facebook 趨勢話題就選到假新聞 | TechNews 科技新報">撤掉人工編輯不到 3天就選到假新聞</a>。）為何 Facebook 用人工招致爭議，但新聞機構不採用人工審核反而不行<span class="page">114</span>？有鑑於演算法造成的<a rel="nofollow" href="https://en.wikipedia.org/wiki/Filter_bubble" accessdate="2016/8/21" title="Filter bubble, 篩選小圈圈, 同溫層">過濾氣泡</a>效應，有些新聞主編甚至認為傳統新聞媒體的重要價值，就在於能為人們帶來不同的觀點<span class="page">233</span>、告知一般人平常不會追尋但卻應該知道的<span class="page">247, 264–265</span>；雖然這功效在今日業已減弱<span class="explanatory">（<span class="creation_title">六、設計過的新聞：當演算法變得至關緊要</span>）</span>。<br />
我想問題在 Facebook 言行不一（屬誠信問題），且影響力過大，其偏見將左右社會輿論<span class="explanatory">（<span class="creation_title">一、緒論：經過程式設計的社會性</span>）</span>。一般人視 Facebook 為機器性的平臺，必須保持公正。相對的，傳統上我們較容許報社、電視臺有自己的立場，畢竟像新聞節目出來播報的還是活生生的人。一般人預期新聞機構的報導是經過嚴格審核的創作，而演算法現在還不受如此高標準的信任。這些心理造成了此種反差。<br />
然而若要問道理想做法，我認為無論新聞機構或網路平臺展現消息時都應去人工化，採用全面且成比例反映事實的演算法<span class="explanatory">（<a>媒體與社會責任</a>）</span>。雖然這會拉低這些媒體的獲利，因此或許必須有公權力介入，否則沒老闆會聽；長久說來卻對社會有好處。人類向來被認為有偏私，就算聲稱完全公平、大公無私，有著人性弱點的人類終究不可信賴<span class="explanatory">（<a>Political Animals</a>）</span>；演算法在這方面不牽扯人的主觀思想，更受信任。假如今天有媒體的演算法能完全公正，且可以道理說服人，那麼就算新聞機構完全不採用人力，我想絕大多數人都能接受。並且就「我們看到的應該是同一個世界」的理想來說，這些演算法皆應以現實為依歸、忠實的依現實情況比例呈現，就同樣的角度獲得的應該是相同的結果（至於採用何種目的篩選應該明確標示）。演算法呈現出的應像現實的縮影，就好比我們在看地圖、<a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E6%AF%94%E4%BE%8B%E6%A8%A1%E5%9E%8B" accessdate="2022/8/12" title="比例模型 scale model">成比例縮小模型</a>般趨近真實。<br />
至於倫理道德議題<q>公說公有理，婆說婆有理</q>，屬於偏好選擇而非有定論的邏輯與物理，必須由社群來判斷<span class="page">244</span>；引導與圓融人們價值觀的工作，應當憑藉另一套公眾參與的系統，例如<a>時事#1</a><span class="creation_title">公眾議題網站設計機制概念</span>。<br />
Bucher 認為演算法會因使用時機而出現偏見<span class="page">115</span>，我想應由制度規範演算法不可用於哪些易出問題的情況。演算法就是該反映現實，若與現實有差異，應當改演算法。問題不在是否人工，而是公正與否。
<p>
雖然我們希望演算法只是忠實呈現我們的意志，然而有時演算法卻可能揭露人心未察覺的部分。會不會演算法做的才是對的，只不過刺中了人類的盲點<span class="page">120</span>，就像大人有時驚訝於孩子把事情看得更清楚？<br />
當演算法把 <a rel="nofollow" class="proper_noun" href="https://en.wikipedia.org/wiki/Phan_Thi_Kim_Phuc" lang="en-US" accessdate="2022/8/1">Phan Thi Kim Phuc</a> 著名的越戰燒夷彈照片判斷成兒童色情裸照<span class="page">119–120, 229–230</span>，許多人認為是演算法出錯；換個角度，這提醒我們未訓練機器學會分辨藝術性圖像。不過許多照片即便交給人類來評斷，亦須有足夠的心智高度與技能才足以判別到底算藝術或色情。甚至特定圖片、故事如 <a rel="nofollow" class="creation_title" href="https://en.wikipedia.org/wiki/Lady_Chatterley%27s_Lover" lang="en-US" accessdate="2022/8/9">Lady Chatterley's Lover</a> 要算藝術或色情，光人類自己就能爭執不休了；同一個人不同時間點或許能把藝術當色情用。這是個偏好問題，沒有數學、邏輯學一樣明確的標準；癥結在人類沒有統一的價值觀。你認同的他人可能不認同，演算法只是凸顯出這種矛盾；打上標記、採<a rel="nofollow" href="https://en.wikipedia.org/wiki/Personalization" accessdate="2016/8/13" title="Personalization">個人化</a>（因應個人特質採不同處置）或許會更理想。此外要判斷算不算藝術品，即便人類也不見得精通，例如要辨別大師贗品。
</p>
本書有些用詞引用哲學家的話語，說好聽點需要反覆咀嚼，卻是不夠淺白易懂，並且少了簡單的例子。例如說「一個實際的存在之所以為人所知，是因為其過程而非狀態」<span class="page">103</span>；我想換成這樣或許更容易理解：一個實存之所以為人所知，是因為其造成了人類在乎的作用，而非其存在的狀態如何。例如一塊地上的石頭，假如是擺在路中間，對人造成困擾，人們自然知道該把它移開，因為這石頭妨礙到了用路人。然而假如是荒郊野外的石頭，即便是彩色的也無人聞問。<br />
本書有些章節改編自學術論文<span class="page">13–14</span>。<a>3 Idiots</a> 批評教科書太過學究氣。我的文章有時也有這樣的問題，是該注意。
<div class="timeStamp">2022/8/9</div>


<h2>四、生活至上：當工程學參與其中</h2>
Facebook 沒跟用戶明說 <q lang="en-US" title="所有朋友和專頁">all of your friends and pages</q> 也經過篩選，引起極大爭議<span class="page">148–149</span>。我想明明表為 <q lang="en-US">all</q> 卻不真的是全部，這是 Facebook 不對；假如改為「<b>熱門</b>朋友和專頁」或許就沒那麼大問題。
<p>
不過關於依重要度排序篩選，我認為這理所當然<span class="explanatory">（<a>Homo Deus</a> <span class="creation_title">第11章 信數據得永生？</span>）</span>。現代人時間寶貴，一天只有24小時，想做的事情又太多。既然<a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E6%B3%A8%E6%84%8F%E5%8A%9B%E7%B6%93%E6%BF%9F" accessdate="2012/11/19" title="attention economics, 注意力經濟: 注意力/關注度為稀缺資源">注意力稀缺</a>，一般人總不希望打開社交平臺就受到上千條新消息轟炸<span class="page">168</span>，又搞不清楚哪些重要。真有人想要被疲勞轟炸，可乾脆提供篩選版與未參選版讓用戶自己選，就好比 Facebook 的<q>最相關</q>與<q>所有留言</q>。就我看來 Facebook 考慮了許多人在乎的變數<span class="page">156</span>，關鍵在<span title="●">怎麼篩選</span>。<br />
假如開放使用者調整演算法的權重（例如關係的經過時間、頻率、各項關係強度<span class="page">156</span>），提供個人化的調適機制<span class="page">209</span>；甚至設定成傻瓜型配套方案一鍵搞定，如此應能降低使用者的不滿意度？不過這可能會有讓使用者試出偏頗設置（強化使用者偏見），以及平臺公司不願公開演算法的問題。<br />
另外依重要程度排序能大幅節省人們的時間，但也該把那些不重要的放在最後，容許人們檢視，而非直接消失不顯示。就我的使用經驗，<a rel="nofollow" href="https://www.facebook.com/help/539680519386145" accessdate="2022/8/31" title="Facebook 粉絲專頁貼文中的「最相關」代表什麼意思？ | Facebook 使用說明">Facebook <q>最相關</q></a>除了按照相關度排序，不該像現在只截取部分留言，其他全顯示<q>你選擇了「最相關」，因此系統可能已過濾掉部分回覆。</q>結果要找到他人對我的回應都很困難，得調回<q>所有留言</q>再個慢慢找；因為我與討論的對手都是在名人文章下面留言的小蝦米。
</p>
上述不快非無解之題。最大難關是 Facebook 之類平臺主要目的是自己賺錢，造福世界只能是不衝突的情況下隨手而為；其演算法指標為增加黏著性、令用戶離不開 Facebook<span class="explanatory">（<span class="creation_title">一、緒論：經過程式設計的社會性</span>）</span>。所以 Facebook 提升了互動熱烈討論的能見度<span class="page">167</span>，顯示人們愛看的同溫層消息。增加熱門話題的見光度、壓抑無聊的（即使那包含嚴肅的），卻不管這些話題對社會的價值<span class="page">205–206</span>。意見相互隔閡、造成偏頗的<a rel="nofollow" href="https://en.wikipedia.org/wiki/Echo_chamber_(media)" accessdate="2017/5/6" title="echo chamber, 同溫層效應, 回音室效應">迴聲室效應</a><span class="page">233, 265</span>，無謂提升庸俗話題的重要度，這就不利民主了<span class="explanatory">（<a>What Money Can't Buy</a> <span class="creation_title">商業化視角深入每個角落</span>）</span>。篩選機制應依比例展現現實<span class="explanatory">（<a>Prius or Pickup?</a> <span class="creation_title">有線新聞、社群與網站之偏頗消息煽風點火</span>）</span>，可這與大公司的盈利目的相悖，怎能兩全？<br />
平臺掌控言論能見度，想增加曝光率就得迎合平臺的演算法<span class="page">210–211</span>。算法能規制使用者行為<span class="page">213</span>，這可視作一種權力<span class="page">177</span>。當生活為寡頭所把持、有組織規模與影響過大時，就會產生類似<q>欠錢的最大</q>、<q>大到不能倒</q>的弊端<span class="explanatory">（<span class="creation_title">一、緒論：經過程式設計的社會性</span>）</span>。若我們只能依賴少數提供者，他們就具備了威脅我們的能力，人們不得不服從；所以社會才需多元化以避免淪落到此般困境。
<div class="timeStamp">2022/8/31</div>


<h2>五、情意地景：日常生活中接觸的演算法</h2>
有些用戶發現 Facebook 因為幾次特殊的搜尋而把自己定性、推薦不喜歡的文章或商品<span class="page">195, 210–211</span>（這可能代表算法對用戶瀏覽新類型時的加權量過大？不過我們得承認有時很難精準判別。），或者女兒去世的消息因許多人推而被列入年度回顧，勾起了父親的感傷回憶<span class="page">200</span>。這種將一般性原則強加在每個人身上，一體適用未考量個人特殊性的做法<span class="page">199, 210</span>，讓人擔心人際關係是否受 Facebook 演算法箝制扭曲<span class="page">204</span>。
<p>
我想原因之一是現在的人工智慧不夠聰明，讀不懂文章的意思<span class="page">195, 202</span>，更不具有人類的偏號與價值觀<span class="page">262</span>，遑論反諷之類<span class="page">263</span>，當然容易鬧笑話。<br />
另外則是演算法見識不足而生偏見。例如無法正確分類（分得出男女，對<a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E5%A4%9A%E5%85%83%E6%80%A7%E5%88%A5" accessdate="2018/11/4" title="Gender and sexual diversity, GSD">多元性別</a>者卻因樣本過少而易判斷錯誤<span class="page">198</span>。），甚至未建立分類（例如年度回顧沒考慮「傷心的回憶」之可能<span class="page">200</span>）。往來的都是共和黨的，固然很高機率也是共和黨人，卻不篤定就是<span class="page">199</span>；然而演算法設計者沒回饋機制以修正錯誤，或者根本沒想過會出這樣的失禮判斷。畢竟由人類撰寫出、不會自動修正的演算法，取樣大多是普遍的情況，碰到特殊狀況就容易出問題。這差錯其實人類也會犯，所以要說演算法非<q>無害</q><span class="page">198</span>，那麼人類也不能說<q>無害</q>。<br />
這些困擾不是不可能改善，只是就當前技術來說需要工程師仔細修正<span class="page">201</span>。想一勞永逸，恐怕得創建出像人類一樣能自我學習、修正錯誤、能理解人類價值觀並成長的人工智能。
</p>
相較之下，資訊不足可就是個兩難了。平臺所知道的只是人們在平臺上的活動，或者頂多像 Facebook 把觸手延伸到網路上其他部分、<a rel="nofollow" href="https://www.techbang.com/posts/7599-face-book-to-track-your-online-activities-no-matter-where-you-are" accessdate="2022/8/31" title="無論是否登入、在那個網站，Facebook 如何追蹤你的活動 | T 客邦">利用 cookie</a> 或 <a rel="nofollow" href="https://3c.yipee.cc/206225/%E5%82%B3%E5%87%BA-facebook-%E5%92%8C-instagram-%E8%A2%AB%E6%8A%93%E5%8C%85%EF%BC%81%E5%88%A9%E7%94%A8-app-%E5%85%A7%E5%BB%BA%E7%80%8F%E8%A6%BD%E5%99%A8%E6%BC%8F%E6%B4%9E%E8%BF%BD%E8%B9%A4%E4%BD%BF/" accessdate="2022/8/31" title="傳出 Facebook 和 Instagram 被抓包！利用 App 內建瀏覽器漏洞追蹤使用者的網路活動 – 三嘻行動哇 Yipee!">app 內建瀏覽器漏洞</a>追蹤人們網路活動。但<q>知人知面不知心</q>，就如同我們只看得到人的一個面向，平臺也不可能掌握人的所有屬性，因此總是有誤判<span class="page">199</span>。越認識你就越能做出準確判斷，問題是有多少人願意將個人隱私攤在平臺眼光下？
<p>
由於演算法既有的缺陷，加上人們脫離不了平臺，只好想辦法自救，採取補償操作以減輕演算法的不良效果<span class="page">210–211</span>。例如無意間點了一篇保守派的貼文，就要多點好幾次自由派的拉回來。而像選擇正確時間與正確拼音更受算法青睞<span class="page">212</span>、沒在發文幾分鐘內就獲得許多讚會下沉、<a rel="nofollow" href="https://zh.moegirl.org.cn/%E5%95%86%E4%B8%9A%E4%BA%92%E5%90%B9" accessdate="2022/9/1">商業互吹</a>能增加彼此的能見度等等，不知道的新手不懂這些技巧，可這些特性其實都能夠被拿來操作（例如<a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E7%B6%B2%E7%B5%A1%E6%89%93%E6%89%8B" accessdate="2020/3/22" title="網路打手 網路水軍">網軍</a>）。大平臺常宣稱不能公開算法，因為一公開就會暴露出這些可被操作的特性。然而就算隱瞞，久而久之還是會被積極摸索的人們試出來。雖然人們向來有耍小聰明<span lang="nan-Hant-TW" title="thau-tsia̍h-pōo, 作弊、投機取巧。利用時機、不守規定、不按部就班而獲取利益。">偷食步</span>的習性，但過去是迎合人類心理，讀心理學有點用；現在則是迎合算法，這屬於一種不自然的狀態<span class="page">213</span>。
</p>
Bucher 強調人們活動也會回過頭來影響演算法<span class="page">225</span>。不是只有人單方面受演算法摧殘，人也對算法的面貌負有責任<span class="page">299–300</span>。在我看來人與算法的互動回饋是不言而喻的， 因為算法本來就是為了完成人所設定的目的<span class="explanatory">（<span class="creation_title">一、緒論：經過程式設計的社會性</span>）</span>，不理想的便會被修正。
<div class="timeStamp">2022/9/1</div>


<h2>六、設計過的新聞：當演算法變得至關緊要</h2>
對於科技產業、或者說搜尋門戶網站對於新聞業的影響，我最大的感觸是現在新聞標題往往喜歡吊人胃口，不把三兩個詞就能簡單說明的事情放在標題，得點進新聞網站才看得到那關鍵的一點點東西。本章提到新聞產業還在社群媒體平臺推出「搶先看」之類專用於吸睛的極短影片，讓用戶願意點進去了解個詳細<span class="page">273</span>。採用影片而非文字的原因是 Facebook 上面影片的<span title="演算法評價">能見度</span>更高<span class="page">273</span><span class="explanatory">（<a>Winners Take All</a> <span class="creation_title">第三章　戴著令人不安貝雷帽的反叛王</span>）</span>。<br />
就當前階段，我覺得新聞業大可把演算法當工具使用，用來增進報導品質。不過我猜總有一天算法撰寫的報導會勝過人類自己。一開始可能只是輔助選材<span class="page">240, 249</span>、編排與呈現方式<span class="page">255–256</span>，等到人工智慧有能力組織流暢文句後，算法就搶得了時效上的先機：如同<a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E9%AB%98%E9%A0%BB%E4%BA%A4%E6%98%93" accessdate="2020/7/17" title="high-frequency trading, HFT">高頻交易</a>速度遠勝人類<a rel="nofollow" href="https://en.wikipedia.org/wiki/Stock_trader" lang="en-US" accessdate="2020/7/17" title="stock trader">股票交易員</a>，誰寫一篇報導的速度能比程式快？屆時新聞產業恐將迎來新一波變局。
<p>
新聞業界常說被 Google、Facebook 搶了飯碗<span class="page">272</span>，抗爭到<a rel="nofollow" href="https://www.bbc.com/zhongwen/trad/business-56179619" accessdate="2022/9/2" title="Facebook 與澳大利亞「重歸於好」 這場戰爭到底誰勝誰負 - BBC News 中文">令政府打算立法要平臺付錢</a>。但我想這或許只是現代人生活模式的漂移。過去人們資訊來源只能靠口耳相傳、世界大事有賴報紙。相形之下現在有網路，許多人成天泡在社群上，想知道什麼會用搜尋的，不再等一個權威機構來告訴自己。甚至有的新聞第一時間是在網路上流傳出、並且發酵的，記者根本措手不及。再說社群上面很忙，人們把時間投在<a rel="nofollow" href="https://newsfeed.org/which-topics-are-popular-on-facebook-watch/" accessdate="2022/9/3" title="Which topics are popular on Facebook Watch? | Newsfeed.org">阿貓阿狗的事情</a>上，除非關注對象、好友特意提到，否則他們沒時間留心這些所謂國家大事。就算人們沒報紙、電視新聞可看，也不會回到無網路的生活。<br />
就這點說來，新聞業的命運有點像網路時代的出版業，或者許多被機器取代的人力工作，以至全球暖化、再生能源政策下的石化業。更早的如馬車廂為汽車廂代替。這些<a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E5%A4%95%E9%98%B3%E4%BA%A7%E4%B8%9A" accessdate="2018/7/13" title="sunset industry">夕陽產業</a>好比<q><a rel="nofollow" href="https://zh.moegirl.org.cn/%E6%97%B6%E4%BB%A3%E7%9A%84%E7%9C%BC%E6%B3%AA" accessdate="2022/9/2" title="時代的眼淚 時淚 刻のなみだ 時の涙">時代的眼淚</a></q>。<br />
新聞業或許必須產業轉型，未來存活下來的不再是傳統觀念、法律定義的新聞媒體產業。就當下網路平臺的世界，得改變立場成為一個消息可靠的權威性資訊提供者，相當於另一個地位較高的用戶<span class="explanatory">（<a>時事#1</a> <span class="creation_title">理想的言論管制法</span>）</span>。不過想維持新聞業存續，這些網路平臺就要付錢給權威資訊提供者，因為他們產出資訊需要資金，而現在這社會人們的消息管道已轉成了搜尋引擎或社交媒體，新聞機構除了依附平臺沒更好的手段賺錢。（我想<a rel="nofollow" href="https://en.wikipedia.org/wiki/News_Media_Bargaining_Code" lang="en-US" accessdate="2022/9/2" title="News Media Bargaining Code">新聞媒體議價法令</a>算是能達成這個效果的嘗試。雖然其立意並非如此，可是殊途同歸。）<br />
這或許代表一般人若能經認證，<a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E6%B0%91%E9%96%93%E8%A8%98%E8%80%85" accessdate="2022/9/2" title="民間記者 citizen journalism">公民記者</a>消息可靠、專家論述有價值，那麼撰寫文章也該有資格從平臺方獲得稿費。
</p>
傳統新聞機構打著的招牌是肩負社會使命的企業，篩選文章的目標是讓社會進行更有益的辯論，使正反兩方民眾了解對方的論點、更容易參與政治議題討論<span class="explanatory">（<span class="creation_title">三、既不黑，也不是箱子：理解或不去理解演算法</span>）</span>。既然目的和 Facebook 之類的盈利企業網路平臺不同，聽起來更有辦法避免因迎合讀者而專門提供些人們喜愛（卻偏頗、<a rel="nofollow" href="https://en.wikipedia.org/wiki/Sensationalism" accessdate="2018/4/4" title="sensationalism">譁眾取寵</a>）的內容、造成<a rel="nofollow" href="https://en.wikipedia.org/wiki/Filter_bubble" accessdate="2016/8/21" title="Filter bubble, 篩選小圈圈, 同溫層">過濾氣泡</a>之類<span class="page">267–268</span><span class="explanatory">（<span class="creation_title">四、生活至上：當工程學參與其中</span>）</span>。<br />
但現實是殘酷的。<a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E6%96%B0%E8%81%9E%E5%B7%A5%E4%BD%9C%E8%80%85" accessdate="2022/9/2" title="journalist 新聞從業人員">新聞工作者</a>應體認到時代變了。就算<a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E5%81%87%E6%96%B0%E8%81%9E" accessdate="2020/12/4" title="fake news 虛假消息">假新聞</a>風波鬧得沸沸揚揚<span class="page">280</span>，也不代表是傳統新聞界絕佳翻身機會。因為已經被同溫層調教過的人們，根本不想看那些與自己想法相悖的意見<span class="explanatory">（<a>Political Animals</a> <span class="creation_title">喜歡一切如自己所料，如何讓我們脫離實事求是</span>）</span>；這就像嘗過民主自由滋味的人民，很難要他們再回去過<a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E7%8D%A8%E8%A3%81%E6%94%BF%E9%AB%94" accessdate="2018/5/31" title="dictatorship">獨裁政體</a>下封閉箝制的生活。過去是沒得選；現在<a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E8%87%AA%E5%AA%92%E4%BD%93" accessdate="2022/9/2">自媒體</a>時代資訊管道那麼多，網路上隨時都能找到支持自己論證、合己意的證據<span class="explanatory">（<a>Not Born Yesterday</a> <span class="creation_title">第九章 政治宣傳與廣告媒體——中共大內宣與劍橋分析真有成效嗎？</span>）</span>，誰願意自我價值根基的觀念被打臉、削弱自尊？當前新聞媒體為了掙口飯，甚至淪落到和這些平臺同調，生存之道為迎合觀眾，拋棄了公正的立場<span class="explanatory">（<a>Prius or Pickup?</a> <span class="creation_title">有線新聞、社群與網站之偏頗消息煽風點火</span>）</span>。重點是民眾也捧場。所以保守派有保守派的新聞頻道，自由派有自由派的。
<div class="timeStamp">2022/9/2</div>


<h2>七、結語：演算法的生活</h2>
一直到第六章，Bucher 似乎將演算法固化、把眼下演算法造成的這些缺失當作根本性問題，沒什麼改進可能<span class="page">276–277</span>，以此下定論。但我看法不同：不滿意就該改到好。終極理想不是 <a rel="nofollow" href="https://en.wikipedia.org/wiki/Pharmakon_(philosophy)" lang="en-US" accessdate="2022/9/2" title="pharmakon (philosophy)">pharmakon</a>（<q>水能載舟，亦能覆舟</q>？），而是如臂使指。這些缺點不是決定性的、永遠如此而可用之為算法定性，而是有辦法改善的。第七章中 Bucher 才提到糾正算法的可能性<span class="page">291</span>。


<h2>小感</h2>
本書帶給我的收穫還比不上 <a>Weapons of Math Destruction</a>，實際價值大概像是那之後這些日子思想的<a rel="nofollow" href="https://en.wikipedia.org/wiki/Incremental_backup" lang="en-US" accessdate="2022/9/2" title="incremental backup">增量備份</a>與統合。因為本書用了許多我沒學過的概念，缺乏理解的鷹架<span class="explanatory">（<a>Not Born Yesterday</a> <span class="creation_title">鷹架理論的延伸應用</span>）</span>，在我看來並非普及性書籍。
<div class="timeStamp">2022/9/2</div>
</div><br />
<div id="reference_list_layer"></div><br class="clear" /><table id="surveyT"><tr><td id="survey"></td></tr></table><hr /><div id="linkback"></div><span id="footer"></span>
</body></html>
