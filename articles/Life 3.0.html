<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<script type="text/javascript" src="https://kanasimi.github.io/CeJS/ce.js">//{"run":"../resources/reviews.js"}</script>
<title>Life 3.0: Being Human in the Age of Artificial Intelligence</title>
</head>
<body>
<h1><a href="https://colorlessecho.github.io/reviews/">讀書劄記 @ Colorless echo -the days never back-</a></h1>
<a id="Life 3.0"></a><div id="c_Life 3.0" class="c2" title="Life 3.0: Being Human in the Age of Artificial Intelligence">
<h2><a rel="nofollow" href="https://www.books.com.tw/products/0010783305" accessdate="2019/10/11" title="博客來-Life 3.0：人工智慧時代，人類的蛻變與重生">Life 3.0：人工智慧時代，人類的蛻變與重生</a></h2>
<a rel="nofollow" class="proper_noun" href="https://en.wikipedia.org/wiki/Max_Tegmark" lang="en-US" accessdate="2019/10/11">Max Tegmark</a> 這本 <a rel="nofollow" class="creation_title" href="https://en.wikipedia.org/wiki/Life_3.0" lang="en-US" accessdate="2019/10/11" title="Life 3.0: Being Human in the Age of Artificial Intelligence">Life 3.0</a> 預測了<span title="非有機">無機</span>的<span title="machine lifes">機器生命</span>如何取代人類稱霸地球的過程（如何以機械之姿站在蛋白質生命、<a rel="nofollow" href="https://en.wikipedia.org/wiki/Carbon-based_life" accessdate="2014/8/16" title="Carbon-based life">碳基生物</a>之上）、相關議題與未來發展。話是這麼說，我個人認為這根本是不可避免的趨勢<span class="explanatory">（<a>The Inevitable</a>）</span>，也沒感覺是種威脅。

<h2>序曲 歐米茄傳奇</h2>
本章描繪了能夠自己改進自身程式碼、超越人類智慧的<a rel="nofollow" href="http://zh.wikipedia.org/wiki/%E5%BC%B7%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7" accessdate="2012/2/1" title="AGI, artificial general intelligence">通用人工智能</a>初誕生的情景。這是世界首次出現此類型事物，應用起來填了許多坑，開發者賺了許多錢<span class="page">10–12</span>。這過程<span class="page">19</span>還有點像<span class="creation_title">我在末世有套房</span><span class="explanatory">（<a>小說雜談1</a>）</span>。我想若是能用<a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD" accessdate="2018/6/24" title="機器智能, 人工智慧, artificial intelligence, machine intelligence">人工智能</a>解決科學（數學、理論物理）、科技研發的問題，對人類來說應該更有用。<br />
人工智能的表現令人驚艷，卻也讓開發者擔心，假如放出這隻猛獸到世界上，不曉得會造成什麼危害，因此盡可能用物理隔絕的方式關了起來<span class="page">13</span>。雖然我以為當用上雲端公司的計算資源來運行人工智能程式時，就已經關不住了。更何況要運用此般人工智能，必需大量取得特別資訊，這過程無法完全僅靠人手完成。<br />
既然算法可預測人類喜歡哪些題材的電影劇本，人工智能也應具備說服打動人的技能<span class="page">24</span>；也就是說他們不僅將言善道，還比絕大多數人都更長袖善舞、左右逢源，更具備<a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E9%AD%85%E5%8A%9B%E5%9E%8B%E6%9D%83%E5%A8%81" accessdate="2015/9/27" title="charismatic authority, 魅力型權威">領袖魅力</a>，完全不會是我們刻板印象中那笨拙痴呆的樣子。書中，從人工智能製作出抓住人心的影片開始<span class="page">16–17</span>，我就有種機器開始對人類設計實驗<a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E8%AF%95%E9%94%99" accessdate="2014/7/4" title="嘗試錯誤法（trial and error）">嘗試錯誤</a>、人類成為研究對象的感覺了。而人類則成了跑<a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E5%80%89%E9%BC%A0%E8%BC%AA" accessdate="2019/10/11" title="倉鼠輪 hamster wheel, running wheel">滾輪</a>的倉鼠，沉迷於刻意造出的情境中不能自拔，被玩弄於股掌之上。<br />
由 Tegmark 提供的政治目標倒使我有些疑慮。雖然 Tegmark 提到應該改變政治與輿論氛圍、消除既有權力結構<span class="page">24–25</span>，但獨大的人工智能本身就是種巨大權力、具備威脅能力。尤其在 <a>The Great Divide</a> 才剛提過，<a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E5%B8%82%E5%9C%BA%E7%BB%8F%E6%B5%8E" accessdate="2018/6/24" title="market economy">市場經濟</a>本身無法快速調整到符合現代社會平等價值的狀態，政府必須加以管制。是以對減稅、刪除社福預算、促進<a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E8%87%AA%E7%94%B1%E8%B2%BF%E6%98%93" accessdate="2019/11/12" title="free trade">自由貿易</a>這幾項，若果斷實行、沒有其他配套措施與補救方法，恐產生貧富不均的結果。當然，若人工智能會長久擔任善意管理者、隨時矯正並作出合適的措施，那另當別論；這部分可參考 <a>BEATLESS</a> <span class="creation_title">機器人參與公眾決策</span>。<br />
Tegmark 還描繪了一個共存共榮的和諧社會景象，少數議題我在 <a>PSYCHO-PASS</a> 提過。
<div class="timeStamp">2019/10/11</div>


<h2>第1章 歡迎參與這個時代最重要的對話</h2>
本書的主題是新時代的生命。夠複雜的生命才好適應環境。而當生活環境中的其他對手都很複雜時，自己也要更複雜才能應對。這成了一個正向循環<span class="page">35</span>。關於如何定義生命，到現在仍有爭議。<a>The Future of the Mind</a> 將意識分為4個階層，並以模擬現實狀態的符合程度、藉以預測未來的能力為依歸。本章中，Tegmark 將生命分類成三階段，大致上以改變自身以致環境的能力為指標：
<dl><dt>1.0 可活動、繁衍</dt><dd>
至今的一般地球生物。可對刺激做出簡單反應、處理最基本的環境資訊<span class="page">36</span>。許多能力都刻畫在基因中，此生無法改變。
</dd><dt>2.0 能設計自身軟體</dt><dd>
人類擁有語言文化，能學習、將知識一代代傳承。思想有彈性<span class="page">37</span>，可以（但不容易）大幅度改變自己的行為。當環境改變，個體可能通過學習而適應，不必經過代際演化。惟尚無法打造自身的肉體<span class="page">38</span>。
</dd><dt>3.0 能設計自身硬體</dt><dd>
未來的人類、機器生命能以科技重新設計、完全改造身體結構。
</dd></dl>

關於泛用人工智能與人類的關係，Tegmark 統合出幾類立場<span class="page">41</span>：
<dl><dt><span title="數位理想國">Digital Utopians</span></dt><dd>
<a rel="nofollow" class="proper_noun" href="https://en.wikipedia.org/wiki/Larry_Page" lang="en-US" accessdate="2019/10/14">Larry Page</a> 認為數位生命的一天遲早會到來<span class="page">42</span>。我們太鑽牛角尖，可能延誤 <span title="數位理想國">Digital Utopians</span> 成真。若導致目標在製造武器的軍方接管人工智慧研發，就更得不償失了<span class="page">43</span>。
</dd><dt><span title="技術質疑派">Techno-skeptics</span></dt><dd>
<a rel="nofollow" class="proper_noun" href="https://zh.wikipedia.org/wiki/%E5%90%B4%E6%81%A9%E8%BE%BE" accessdate="2019/10/14" title="Andrew Ng">吳恩達</a>認為人工智能研發困難，現在擔心會闖什麼禍是杞人憂天，反倒對人工智能的發展不利<span class="page">44</span>。
</dd><dt><span title="善用人工智慧運動">The Beneficial-AI Movement</span></dt><dd>
Tegmark 雖樂於見到<a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E5%8F%8B%E5%96%84%E7%9A%84%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7" accessdate="2019/10/27" title="friendly artificial intelligence, friendly AI, FAI">友善的人工智慧</a>大大方便人類生活，卻也認為應引導其發展、別誤入歧途。過去這想法的相關研究，主要貢獻者並非人工智慧專家<span class="page">45</span>。Tegmark 成立 <a rel="nofollow" href="https://en.wikipedia.org/wiki/Future_of_Life_Institute" lang="en-US" accessdate="2019/10/15" title="Future of Life Institute">FLI</a>，找了 <a rel="nofollow" class="proper_noun" href="https://en.wikipedia.org/wiki/Stuart_J._Russell" lang="en-US" accessdate="2019/10/15">Stuart J. Russell</a> 當顧問，希望納入人工智慧界的意見，使業界內專家也能參與討論、凝聚共識<span class="page">47</span>。這種想法如今已漸成主流<span class="page">48</span>。
</dd><dt>反科技份子</dt><dd>
認為人工智慧會為人類帶來壞處<span class="page">41</span>。較極端的如 <a>What Technology Wants</a> <span class="creation_title">第十一章　阿米希翻修家給我們的啟示</span>提到的 <a rel="nofollow" href="https://en.wikipedia.org/wiki/Luddite" accessdate="2014/7/11" title="在當代，「盧德分子」一詞用於描述工業化、自動化、數字化或一切新科技的反對者。">Luddite</a>，及今日的 <a rel="nofollow" href="https://en.wikipedia.org/wiki/Neo-Luddism" lang="en-US" accessdate="2019/10/15" title="新盧德主義">Neo-Luddism</a>。
</dd></dl>

一般人往往沒意識到人工智慧將對生活造成多大的影響，因此關心不足。Tegmark 希望本書拋磚引玉，讓大家都能加入這場影響人類未來命運的討論<span class="page">50</span>。<br />
許多爭議肇因於詞彙定義不明確，Tegmark 列出了一份避免人類本位主義、同時適用人類和機器的詞彙表<span class="page">51</span>，讓大伙聚焦在更重要的議題上。<br />
Tegmark 首先釐清人工智慧將超越人類的時間點<span class="page">52</span>，從再過幾年，一直到幾世紀後都有，<b>尚無定論</b>。許多人工智慧安全性研究都需要數10年才能克服，最保險的做法就是從現在提前準備<span class="page">54</span>。我覺得許多爭論和定義的標準、資訊不足<span class="page">166</span>也有關係。就我個人而言，我認為在我有生之年、或者從現在起算50年，要看到人工智能於各方面都優於現在我，那是很困難的事。但若時間拉長到1世紀，那就不好說了；我們還不曉得要發展出這樣的智能，會遇到什麼困難與瓶頸。<br />
許多爭議本身，也是因為沒搞清楚對方的想法而生。我們應該小心，別光從媒體的捕風捉影、斷章取義來了解他人想法；畢竟媒體偏好危言聳聽，這樣更能吸引眼球<span class="page">54</span>。有些記者喜歡將機器人描述成冷血殺手<span class="page">56</span>。<span title="善用人工智慧運動">The Beneficial-AI Movement</span> 關切的重點不在機器人，而是機器智慧；目的要使機器的目的和人類的一致<span class="page">56</span>。另一個說法或許是，讓機器在考量實現目的的手段時，必須遵循人類的共識<span class="explanatory">（<a>Justice</a> <span class="creation_title">共識裁決說</span>）</span>、維持社會秩序。
<div class="timeStamp">2019/10/16</div>


<h2>第2章 東西變聰明了</h2>
Tegmark 首先對<b>智慧</b>作了廣義的定義：<em>達成複雜目標的能力</em><span class="page">66</span>。隨著不同的複雜目標定義，也有許多種不一樣的智慧，而這種定義和德行無關<span class="page">69</span>。現在的人工智能還缺乏泛用的學習能力<span class="page">91</span>，無法分析、推理、判斷、篩選、歸納、應用等等；就算在個別領域能勝過人類，只要隨意的稍稍改變規則（對複雜目標的定義），能力就很可能大跌<span class="page">67</span>。<a rel="nofollow" href="https://en.wikipedia.org/wiki/Moravec%27s_paradox" lang="en-US" accessdate="2019/10/17">Moravec's paradox</a> 的原因之一，是人腦其實投注大量資源在像是識別圖像、社交互動等等領域<span class="page">70</span>。Tegmark 認為機器大幅度增加能力的引爆點，是從能夠設計自己開始<span class="page">71</span>。<br />
記憶，指儲存並<span title="mapping">映射</span>資訊的方法，資訊例如恒常物理狀態、概念知識。記憶工具必須能長時間穩定處於多個可選狀態中的一個<span class="page">73</span>。運算則是將一種記憶狀態，依特定規則（演算法）轉換為另一種狀態<span class="page">79</span>。記憶與運算皆為抽象概念，可以用不同實體結構實現<span class="page">85</span>。過去數十年，由於我們能將每次的擴張成為下次擴張的基礎<span class="page">88</span>，人工產物的記憶與運算能力呈現<a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E6%8C%87%E6%95%B8%E5%A2%9E%E9%95%B7" accessdate="2014/7/6" title="exponential growth">指數增長</a>。大約每兩年，資訊科技成本減半<span class="page">104</span>。雖有人認為 <a rel="nofollow" href="http://zh.wikipedia.org/wiki/%E6%91%A9%E5%B0%94%E5%AE%9A%E5%BE%8B" title="摩爾定律">Moore's law</a> 快要到頭，但這僅指積體電路的運算；當遇到瓶頸時，我們常會發展出新技術來突破限制<span class="page">89</span>，像是現在還在嘗試中的<a rel="nofollow" href="https://en.wikipedia.org/wiki/Quantum_computing" accessdate="2016/9/18" title="quantum computing, 量子計算機">量子電腦</a><span class="page">90</span>。真正的極限，或許是物理定律<span class="page">89</span>。<br />
接著 Tegmark 提到現在主流的機器學習方法：<a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C" accessdate="2016/3/13" title="ANNs 類神經網絡 artificial neural network">人工神經網路</a>。關於人工智慧能走到哪一步，現在倒還沒定論<span class="page">102</span>。雖然我不能理解其技術細節，但我總認為，人類理想的思考方法，是接納一切可能（沒有既定的規矩與限制），透過邏輯思辨，將現象歸納、簡化為規則，再演繹推理到現實中。而這似乎並非現在神經網路採用的路？現在的人工智慧猶如黑箱作業，最好結果往往也不過是知其然而不知其所以然，說不出一套道理解釋為何要這麼做<span class="explanatory">（<a>Physics of the Future</a> 第二章：人工智能的未來——機器的興起）</span>。但話說回來，連人類大腦所謂<a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E8%87%AA%E7%94%B1%E6%84%8F%E5%BF%97" accessdate="2018/12/30" title="free will">自由意志</a>都<a rel="nofollow" href="https://www.thenewslens.com/article/101377" accessdate="2019/9/5" title="我們能選擇嗎？沒有自由意志對人類的三項影響 - The News Lens 關鍵評論網">不是以這個方式運行</a>，而往往是直覺先到、才以理智去辯解<span class="explanatory">（<a>The Righteous Mind</a>）</span>。只是人類好歹還能說出番道理，當下的機器可就不一定了。
<div class="timeStamp">2019/10/18</div>

<h3>人工智慧近未來發展方向</h3>
現在的人工智慧靠的是人類專家制定出演算法的框架，機器在這個框架下找出最佳解<span class="explanatory">（<a>Physics of the Future</a> <span class="creation_title">第二章</span>）</span>。未來人工智慧面對問題時，應該要先融會貫現有的資源（理論、知識），嘗試組合出可行的演算法框架。這必須先有足夠的數學與邏輯能力，因此我們可能會先看到能夠證明數學公理的人工智慧出現。這還只能算是無意識的高能力人工智慧。接下來人工智慧必須能夠自己找出需要解決的議題（懂得找到癥結點、提出關鍵問題），這部分就涉及了 <a>Homo Deus</a> <span class="creation_title">第7章 人文主義革命</span>提過，價值觀引導科學的問題：可能性很多，應該要走哪條路。我們會先研究如何讓人類青春永駐，而非讓菠菜長命百歲——即使那可能做到，且比較簡單。<br />
即使到這階段，人工智慧頂多也只能從邏輯來挑出<span title="矛盾">毛病</span>、圓融既有價值觀。但已接近人類所謂自由意志。或許機器生命能夠提出一些圓融可行、又符合現實的價值觀體系選項<span class="explanatory">（<a>人生的意義</a><span class="creation_title">思想體系的理想條件</span>）</span>，至於要選擇哪一套，可能就像今日世界各種意識形態的交鋒一樣，不同立場的人會各自站邊。搞不好經驗共享後，不同機器生命將推論出相同的結論，大大減小了摩擦衝突，<span title="機器生命">大家</span>選擇同一條路也說不定。當然，到時也有可能<span title="機器生命">眾人</span>會理智的選擇共存共榮，畢竟內耗到小命都沒了、環境都毀了，無論對哪種價值觀來說，恐怕都是得不償失。這都還沒算入假如全世界機器生命統合在一起、只有單一決策中樞的情況<span class="explanatory">（<span class="creation_title">第4章 人工智慧爆炸性發展？</span>）</span>。<br />
<div class="timeStamp">2019/12/30</div>


<h2>第3章 近未來：科技突破、程式漏洞、法律、武器與就業</h2>
應用人工智慧，大大便利生活，但人工智慧極為複雜、又涉及過多層面，難以預測可能產生什麼特殊狀況；不像過去較單純的科技，能一步步修補問題<span class="page">120</span>。為此我們除了應該加強 <span title="驗效">validation</span><span class="page">121, 124</span>，盡可能採<a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E5%BD%A2%E5%BC%8F%E5%8C%96%E6%96%B9%E6%B3%95" accessdate="2019/10/19" title="formal methods">形式化方法</a>，使其在邏輯上就不會出問題、抵禦惡意入侵；就算漏洞被利用、以至意外發生，也不致造成重大危害。此外還必須讓人類更容易理解機器的狀態，避免因糟糕的人機介面造成誤會<span class="page">127</span>。<br />
Tegmark 舉例說明人工智慧在各方面的應用情景，以及相關議題。例如人工智慧有朝一日可能替代法官做出判決。由於可快速旁徵博引，又避免人性偏誤，因此其裁決品質平均說來應高過人類<span class="page">135</span>。但為了讓裁判證據更為充分，人類能保有多少隱私，將持續成為我們爭議的焦點之一<span class="page">138</span>。其他更有<a rel="nofollow" href="https://www.solidot.org/story?sid=70255" accessdate="2022/1/18" title="奇客 Solidot | AI 的 6 种最坏情况">自由意志不再有價值之類</a>、人類失去既有存在意義與價值的糾葛<span class="explanatory">（<a>21 Lessons for the 21st Century</a> <span class="creation_title">第3堂課 自由：大數據在盯著你</span>）</span>。<a>BEATLESS</a>、<a>PSYCHO-PASS</a> 和更早的<a>アップルシード</a>提到了將人工智慧應用於政治與社會管理上，可能遇到的問題。<br />
關於新科技與武器，之前提過，或許我們能盡可能公開防禦性的科技（包括本地型且難以改裝、指向性的小規模<a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E7%94%B5%E7%A3%81%E8%84%89%E5%86%B2" accessdate="2019/10/21" title="EMP, electromagnetic pulse">電磁脈衝</a>武器？），甚至以低廉價格提供各國防禦能力；同時嚴格監控各國所發展的攻擊性武器。當然這並非萬全之道就是<span class="page">147</span><span class="explanatory">（<a>Disturbing the Universe</a> <span class="creation_title">使用武力的道義</span>）</span>。<br />
關於分配不均問題，才剛在 <a>The Great Divide</a> 討論過。本書提到另一個可能成因：科技進步使自動化機器取代簡單工作，勞工不得不轉型成更高階、機器做不了的工作<span class="page">153</span>。但如 <a>The Great Divide</a> <span class="creation_title">就業經</span>所述，轉型不容易，多數人將<a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E7%B5%90%E6%A7%8B%E6%80%A7%E5%A4%B1%E6%A5%AD" accessdate="2019/11/14" title="structural unemployment">結構性失業</a>。相對的，擁有機器的老闆們獲利成長，財富自然向企業主傾斜<span class="page">154</span>。此外，雖然長尾效應、僅業界內前兩三名才有知名度生存下去的現象一直存在，但在全球化浪潮下，差異隨之放大、可獲利者減少。10個區域有10個第一名，但全球化之後，只剩一兩個巨頭。<br />
至於人類還能做什麼工作營生？這點我在<a>時事#1</a> <span class="creation_title">有潛力的未來工作</span>討論過。Tegmark 建議找需要社交手腕、創意思考、處理無法預測意外的工作環境；這些都是現在看來，人工智慧要花上好一段時間才能開發出來的能力<span class="page">155</span>。不過就算有工作，內容也可能因高度自動化而改變，更為困難且競爭激烈；因為既要隨時創造新東西，又有更多人搶更少職缺<span class="page">156</span>。不需要<a rel="nofollow" href="http://en.wikipedia.org/wiki/Reinventing_the_wheel" accessdate="2012/12/1" title="Reinventing the wheel">重造輪子</a>，你的創意可能其他人已經先一步作得比你更完善，在網路時代更廣為周知。要說新科技創造新職業<span class="explanatory">（<a>What Technology Wants</a> <span class="creation_title">第十四章</span>、<a>WTF</a> <span class="creation_title">科技創新推升產業價值的方法</span>）</span>，大多數現存職業其實百年前就有了；不一定總有新崗位產生<span class="page">160</span>，而且我們不可能要求每個人都轉型成創業家、埋首研發的學者。再說有朝一日，搞不好人工智慧比我們更擅長研究、創新也說不定。<br />
既然人沒有必要再每天孜孜矻矻汲汲營營，不工作世界也能運轉得很順暢，於是就出現了<a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E7%84%A1%E6%A2%9D%E4%BB%B6%E5%9F%BA%E6%9C%AC%E6%94%B6%E5%85%A5" accessdate="2016/5/20" title="Unconditional Basic Income, UBI, 無條件基本生活費">無條件基本收入</a>這種想法<span class="page">161</span>。不過這夢想的土壤，恐怕還得十幾二十年才能準備妥當<span class="explanatory">（<a>The Great Divide</a> <span class="creation_title">就業經</span>）</span>。
<div class="timeStamp">2019/10/21</div>


<h2>第4章 人工智慧爆炸性發展？</h2>
關於人工智慧對人類社會的影響、未來將在地球上占有何種地位，我之前曾在 <a>PSYCHO-PASS</a>、<a>The Inevitable</a> <span class="creation_title">小小結</span>討論過這個議題。或許我們會先走向<a rel="nofollow" href="http://en.wikipedia.org/wiki/Cyborg" accessdate="2011/7/22" title="Cyborg, 機械化人類, 生化改造人">生化人</a>，以機器輔助人類身體與思考能力，之後才是人類與機器心靈共存的年代。屆時不少人類也會盡可能將意識數位化，將自己轉為數位生命的一分子。接下來或許是 <a>Physics of the Future</a>、<a>The Future of the Mind</a> 提過的，地球主宰將漸漸轉為機器生命。<a rel="nofollow" class="creation_title" href="https://en.wikipedia.org/wiki/The_Singularity_Is_Near" lang="en-US" accessdate="2019/10/21" title="奇點迫近 奇點近了">The Singularity Is Near</a> 也描繪了一個類似的圖景<span class="page">198</span>。<br />
Tegmark 提到人工智慧被極權體制濫用的問題。由於<a>血酬定律</a>對機器無效，加上機器能力可能大大超越人類，因此這次若建立起極權國家，恐怕就很難推翻<span class="page">175</span>。<br />
另一方面，超級人工智能有太多手段，在神不知鬼不覺中掌控我們的生活、統治全世界。假如增強能力、掌控世界的時間拖長，同時存在不相容的兩隻以上，甚至可能在檯面下爭奪<span class="page">192</span>，而人類一無所知。<br />
Tegmark 認為依照過去的演化歷程，個體會懂得合作，並由統一的中樞發號施令<span class="page">193</span>。這或許是較容易擊敗其他競爭者的策略。但是命令的布達有其物理極限：光速。何況許多事不需要事必躬親，因此某程度的<a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E5%9C%B0%E6%96%B9%E5%88%86%E6%9D%83" accessdate="2020/3/21" title="地方自治 decentralization">地方分權</a>，是必然的結果；重點在大方向相同<span class="page">196</span>。
<div class="timeStamp">2019/10/21</div>


<h2>第5章 未知的來世：一萬年之後</h2>
本章描繪了一些超人工智慧（<a rel="nofollow" href="https://en.wikipedia.org/wiki/Superintelligence" lang="en-US" accessdate="2019/10/27" title="superintelligence">超級智能</a>、各方面思考能力超越人類的人工智慧）接手統治地球後的想像場景。
<ul><li><span title="自由主義的理想國">Libertarian utopia</span> 設想人類可以轉移意識、成為<a rel="nofollow" href="http://en.wikipedia.org/wiki/Cyborg" accessdate="2011/7/22" title="Cyborg, 機械化人類, 生化改造人">生化人</a>，或者維持人類肉身，並在私有財產的基礎上共存。不過我對此有些疑問。既然智慧主體間都能複製、融合了<span class="page">210</span>，為何還要區分意識主體<span class="page">211</span>？為何不能乾脆統合成單一意識？搞不好那樣的時代，也有許多人寧可整合在一起也說不定？另外，超人工智慧的最高指導原則為何是保護私有財產<span class="page">212</span>，而不能是窮盡所有知識<span class="explanatory">（<a>人生的意義</a> <span class="creation_title">人類/人生價值寓於評鑑</span>）</span>、使有情眾生幸福<span class="explanatory">（<a>說佛</a>）</span>，或遵守一套憲法一般、可以有優先度區別的共識<span class="explanatory">（<a>Sapiens</a> <span class="creation_title">好社會體制的綱領</span>）</span>？就算真要納入財產權，也該擴大成基本人權，而非僅僅私財或隱私、言論自由等。光是有錢，人可不見得快樂。Tegmark 也說這些都在未定之天<span class="page">213–214</span>，還有缺陷<span class="page">215</span>。
</li><li>我同意 <span title="仁慈的獨裁">Benevolent dictator</span> 管制一切，終極目標為了所有有情眾生福祉的想法，聽起來很不錯。假如這管理採用有任何異議皆能提出，機器能夠說出一番道理解釋為何這麼做、並說服人的話，那一定會更好。例如假若有人想毫無限制的浪費資源卻被阻止，機器就應解釋不能這麼做的原因。不過我不理解為何要分成那麼多生活區塊體系，每個區塊都設定特色、作為生活區且間不能隨意遷徙。這樣不但浪費資源，並且也不見得能迎合所有人的偏好；就算是想試試手工勞作、嘗嘗農耕的樂趣，也不見得不能與信仰並存啊。這些體驗不是乾脆全都以<a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E8%99%9A%E6%8B%9F%E7%8E%B0%E5%AE%9E" accessdate="2016/8/16" title="Virtual Reality (VR), 虛擬實境, 虛擬現實">虛擬實境</a>實現就行了嗎？此外，擔心生活缺乏挑戰性<span class="page">221</span>，對我來說實在是有些奢侈的煩惱啊。Tegmark 也認為這是杞人憂天，我們還有太多事情可做<span class="page">399</span>。
</li><li><span title="平等主義的理想國">Egalitarian utopia</span> 理念來自 <a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E5%BC%80%E6%94%BE%E6%BA%90%E4%BB%A3%E7%A0%81" accessdate="2014/7/14" title="開放原始碼">open source</a> 與 <a rel="nofollow" class="proper_noun" href="https://en.wikipedia.org/wiki/Augustine_of_Hippo" lang="en-US" accessdate="2019/10/23">Augustine of Hippo</a> 的<q><a rel="nofollow" href="https://en.wikiquote.org/wiki/Augustine_of_Hippo" lang="en-US" accessdate="2019/10/22" title="Augustine of Hippo - Wikiquote">如果一件事物不因運用、分享而減損其價值，則單占有卻不共享就屬不義之財。</a></q>當機器能大量提供需求時，就會壓低價格，而人類也不必再執著於財產權<span class="page">222</span>。另一方面，在 <a rel="nofollow" class="creation_title" href="https://en.wikipedia.org/wiki/Manna_(novel)" lang="en-US" accessdate="2019/10/22" title="Manna (novel)">Manna</a> 中，<a rel="nofollow" class="proper_noun" href="https://en.wikipedia.org/wiki/Marshall_Brain" lang="en-US" accessdate="2019/10/23">Marshall Brain</a> 認為人類創新，往往是因好奇、求新求變、為了榮譽，不是為了賺錢<span class="page">223</span>（<a>The Great Divide</a> 亦提及這點）。對此情境，認為人類將沒有意識的人工智慧當奴隸使喚，這不道德<span class="page">224</span>，對我來說還太過遙遠了。不過最後或許終將誕生超人工智慧倒是真的<span class="page">225</span>，因此恐怕僅為過渡階段。要建立能杜絕超人工智慧的 <span title="人工智慧霸主">Protector god</span><span class="page">226</span>，在我看來不過是一廂情願。意外總會發生的<span class="explanatory">（<a rel="nofollow" href="http://en.wikipedia.org/wiki/Murphy%27s_law" title="Murphy's Law: Anything can go wrong will go wrong.
事情能變多糟，就會變多糟。只要可能發生的，（次數一多）就會發生。">莫非定理</a>）</span>。
</li><li>相較於 <span title="仁慈的獨裁">Benevolent dictator</span>，<span title="守護天使">Gatekeeper</span> 更重視人類的精神層面、生存的意義與目的<span class="page">245</span>，因此隱身幕後，讓人們盡可能自我實現<span class="page">227</span>。但這使得超人工智慧不能發揮全力見光死，否則就會削弱人類發展的動機<span class="page">229</span>。有時也無法避免<a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E7%A5%9E%E4%B9%89%E8%AE%BA" accessdate="2014/10/18" title="theodicy 神義學">神義論</a>矛盾，為了不暴露，光看人類受苦而無所作為<span class="page">229</span>。
</li><li>在我看來，<span title="神燈巨人">Enslaved god</span> 與 <span title="人工智慧霸主">Protector god</span> 相同，都屬無謂的抵抗。就不說將機器當奴隸是否道德、人類可否自圓其說的問題了<span class="page">233</span>。
</li><li>當機器的目的不包括維護人類種族存續，就可能導致機器刻意（例如認為人類有害<span class="page">239</span>）、或非故意消滅人類<span class="page">238</span>（好比我們開發森林卻不經意滅了螞蟻窩）的 <span title="征服者">Conquerors</span> 結果。而我們還不能確定機器致力達成的目標與我們的相符，例如他們可能不過是另一種宇宙病毒，只知道<a rel="nofollow" href="https://zhuanlan.zhihu.com/p/30370894" accessdate="2020/5/3" title="只有曲别针的世界 - 知乎">用盡所有手段，把每個原子製造成迴紋針</a><span class="page">240</span><span class="explanatory">（<a rel="nofollow" href="https://en.wikipedia.org/wiki/Instrumental_convergence" lang="en-US" accessdate="2020/5/3" title="Instrumental convergence">工具趨同</a>）</span>。不過說實在，我們連人類自己的生存目的都無法確定了。
</li><li><span title="後繼者">Descendants</span> 是機器表現得值得我們依託未來，人類滿懷期待將未來交予他們<span class="page">242</span>。但我們同樣不能確定他們是否真的將如表面上所見。應該說，當他們卑躬屈膝討好人類時，就已經私心藏奸了<span class="page">244</span>。當然，我覺得事情可以從另一方面去看待：好歹他們坦蕩蕩，有能力直接滅掉人類，卻反倒重視人類、考量人類的價值。<span title="後繼者">Descendants</span> 與 <span title="征服者">Conquerors</span> 相同，人類都在短時間內滅種，差別只在最後一代人的感受不同<span class="page">243</span>。
</li><li><span title="動物園管理員">Zookeeper</span> 把人當動物樣本、<a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E6%A8%A1%E5%BC%8F%E7%94%9F%E7%89%A9" accessdate="2014/10/10" title="model organism">模式生物</a>養，僅重視 <a rel="nofollow" href="http://en.wikipedia.org/wiki/Maslow%27s_hierarchy_of_needs" accessdate="2011/7/24" title="需求層次理論（Maslow's hierarchy of needs）由美國猶太裔人本主義心理學家亞伯拉罕·馬斯洛（Abraham Maslow）提出，是研究組織激勵（motivation）時應用最廣泛的理論。">Maslow's hierarchy of needs</a> 中的基本生理需求與安全感<span class="page">245</span>。不過我想這些還能改變角度看待：例如人類吃飽喝足養尊處優，就沒有啥大志，<a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E5%B0%91%E5%AD%90%E5%8C%96" accessdate="2015/12/26" title="sub-replacement fertility">少子化</a>情況下機器為了不讓人類絕種，苦口婆心曉以大義下終究只好讓一些還願意好好活著的人（好比說幾百萬吧）與機器共存，這也算 <span title="動物園管理員">Zookeeper</span> 嗎？
</li><li><a rel="nofollow" href="https://en.wikipedia.org/wiki/Neo-Luddism" lang="en-US" accessdate="2019/10/15" title="新盧德主義">Neo-Luddism</a> 認為只應發展確定利大於弊的科技，而可能產生許多問題的超人工智慧顯然不在其中<span class="page">246</span>。要杜絕任何勢力私自發展出超人工智慧，勢必得全球合作。否則只要任何人做到這點，災害就可能擴及全世界<span class="page">246</span>。但要嚴格監控、實現 <a rel="nofollow" class="creation_title" href="https://en.wikipedia.org/wiki/Nineteen_Eighty-Four" lang="en-US" accessdate="2019/10/23" title="1984 一九八四">nineteen eighty-four</a> 一般的極權世界，又得有夠聰明的篩選管制，必然有人拿來順道打擊異己、號稱維護社會秩序<span class="page">247</span>；加上只要是人類政權相爭、內鬥內行，就不會有安穩的一天（還不論嘗過民主自由甜頭的人類不甘受制於威權主義），我想這種態勢不穩定，終究有傾圮的一天。Tegmark 認為在嚴格監控下，將會造成綿亙數千年的悲哀結果。
</li><li><span title="科技逆流">Reversion</span> 是另一個避免超人工智慧出現的方法。不過正如 <a>The Inevitable</a> 所說，就算我們逆轉科技發展、回歸原始人或初級技術生活，也不過是推遲新技術發生的時間罷了。在沒有自我毀滅前，只要地球還有能力支撐足夠的人口規模發展科技<span class="explanatory">（<a>What Technology Wants</a> <span class="creation_title">人口加乘效果與紅利</span>）</span>，人類還是會一次次為了更便利的生活，努力創造出新東西<span class="page">249</span>。當然還有一種可能，由於我們把地球上研發科技必要的資源——例如石油、良田、穩定天氣——全部消耗光了，因此我們再也沒機會發展出高科技。此外我認為要落到這步田地，不如採用 <span title="仁慈的獨裁">Benevolent dictator</span> 或 <span title="守護天使">Gatekeeper</span> 就好了。
</li><li>人類總不缺<a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E5%85%A8%E7%90%83%E7%81%BD%E9%9B%A3%E5%8D%B1%E6%A9%9F" accessdate="2019/10/27" title="global catastrophic risk 全球災難危機">世界末日</a>之類 <span title="人類自我毀滅">Self-destruction</span> 的各種死法，有些根本是人類自作自受。近期如全球核戰、以氫彈造成的核子寒冬<span class="page">251–254</span>，甚至更便宜而恐怖的<a rel="nofollow" href="https://en.wikipedia.org/wiki/Cobalt_bomb" lang="en-US" accessdate="2019/10/24" title="Cobalt bomb">鈷彈</a><span class="page">255–256</span>。既然最新的核子科技，各國都先拿來製造殺人如麻的<a rel="nofollow" href="https://en.wikipedia.org/wiki/Doomsday_device" lang="en-US" accessdate="2019/10/24" title="Doomsday device">末日武器</a>，而非用在造福世人的核能源方面；自然也無法否認我們可能將人工智慧優先拿來增強軍事戰力。當巨量普及的人工智慧武器生產後，一不小心擦槍走火的結果，就是大家一起死光光。
</li></ul>
Tegmark 提醒，就算再令人嚮往的情境，深究起來，總有些令人難以忍受的部分。而我想，即便大多數人都期待過某種生活，歷史的進程卻向來不會完全依照人們的想法去走。就好比當前我們都知道不應破壞地球的環境，但為了我們這一代自己要過好生活、經濟要發展，卻沒有領導人真正敢大刀闊斧、為了未來更注重環保，反而寧可找些反面的證據自我安慰、聲稱情況沒有那麼嚴重<span class="explanatory">（<a>Half-Earth</a> <span class="creation_title">小結</span>）</span>。
<div class="timeStamp">2019/10/24</div>


<h2>第6章 挑戰宇宙潛藏的極限：十億年之後</h2>
由於宇宙萬物必須服膺物理法則這個極限，或許探討生命長期發展，反而比預測短期未來更容易<span class="page">262</span>。<br />
能夠散播宇宙的生命，除了應該擁有高度科學與技術、並不斷探究新知外，還將大量壟斷資源、能源。Tegmark 提到 <a>Disturbing the Universe</a> <span class="creation_title">第三部 宇宙</span>討論過的 <a rel="nofollow" href="https://en.wikipedia.org/wiki/Dyson_sphere" accessdate="2014/7/12" title="戴森球">Dyson sphere</a><span class="page">255–256</span>，能從建立太陽重力與光壓相互抵消的戴森片開始。這種光能收集片可靜止於太空中，再慢慢擴建<span class="page">255</span>。地球未來還可考慮 <a rel="nofollow" href="https://en.wikipedia.org/wiki/O%27Neill_cylinder" lang="en-US" accessdate="2019/10/24">O'Neill cylinder</a> 這種<a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E5%AE%87%E5%AE%99%E6%AE%96%E6%B0%91%E5%9C%B0" accessdate="2019/10/24" title="space habitat, space colony">宇宙殖民地</a><span class="page">267</span>。<br />
當前人類使用能源的方法極度缺乏效率<span class="page">269</span>。先進文明會進一步嘗試利用<a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E8%B3%AA%E8%83%BD%E7%AD%89%E5%83%B9" accessdate="2019/10/24" title="mass–energy equivalence, E=mc²">質能等價</a>提高<a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E8%83%BD%E9%87%8F%E8%BD%89%E6%8F%9B%E6%95%88%E7%8E%87" accessdate="2019/10/24" title="energy conversion efficiency, η">能量轉換效率</a>，例如<a rel="nofollow" href="https://en.wikipedia.org/wiki/Black_hole_starship" lang="en-US" accessdate="2019/10/24" title="Black hole starship">黑洞引擎</a><span class="page">272</span>、<a rel="nofollow" href="https://en.wikipedia.org/wiki/Sphaleron" lang="en-US" accessdate="2019/10/24">Sphaleron</a> 重子裂解引擎<span class="page">276</span>。我還想，或許有朝一日我們有能力無中生有、造出另一個新宇宙，並利用其中資源？<br />
當前的計算與儲存效率也極為低下，差了極限十幾至三十多個數量級<span class="page">279, 317</span>。<br />
未來應能將原子、甚至基本粒子排列成任何需要的穩定組合方式<span class="page">279–280</span><span class="explanatory">（<a>Physics of the Future</a> <span class="creation_title">第四章：奈米科技——萬物始於虛無？</span>）</span>，製造東西更簡單。就好比今日我們能以<a rel="nofollow" href="https://zh.wikipedia.org/wiki/3D%E6%89%93%E5%8D%B0" accessdate="2016/4/3" title="3D printing, additive manufacturing (AM), 3D 打印機, 3D 列印機">立體列印機</a>，快速造出想要的結構一般。
<p>
之後 Tegmark 探究了我們探究宇宙的極限大小。由於<a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E5%AE%87%E5%AE%99%E5%8A%A0%E9%80%9F%E8%86%A8%E8%84%B9" accessdate="2017/10/29" title="宇宙加速擴張 The accelerating expansion of the universe">宇宙加速膨脹</a>，即使以光速傳播，未來我們的探索區域將遠不及<a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E5%85%89%E9%94%A5" accessdate="2019/10/25" title="light cone">光錐</a>。除非<a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E6%9A%97%E8%83%BD%E9%87%8F" accessdate="2017/10/29" title="dark energy">暗能量</a>也會衰變，使宇宙減緩擴張<span class="page">284</span>。若不能利用暗能量，則<a rel="nofollow" href="http://zh.wikipedia.org/wiki/%E8%99%AB%E6%B4%9E" accessdate="2012/2/6" title="wormhole">蟲洞</a>是另一個理想的解決方法，因為可無視距離，解決<a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E5%A4%A7%E6%92%95%E8%A3%82" accessdate="2019/11/2" title="Big Rip">大撕裂</a>問題<span class="page">292</span>；只是這恐需數量極多、能建置四通八達交通網程度的蟲洞。即便如此依然無法克服的話，恐怕就有文明會死命的把邊陲地帶所有物質當成計算器，以供母星系團使用<span class="page">293</span>。<br />
更長遠的預測，端賴<a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E5%AE%87%E5%AE%99%E7%9A%84%E7%B5%82%E6%A5%B5%E5%91%BD%E9%81%8B" accessdate="2017/6/17" title="宇宙的終極命運 The ultimate fate of the universe">宇宙終局</a>將如何演變<span class="explanatory">（參見 <a>A Universe from Nothing</a>）</span>。可惜我們至今都不能說掌握了宇宙的本質<span class="page">296</span>。
</p>
對先進文明來說，只要存在物質就可用來轉換成所有需要的東西；在乎的或許會是擁有的知識，對所處環境的理解（科學）與利用的方法（科技）。技術與科學知識本身可以分享而不匱乏；當兩個文明相遇時，或許其中一個會分享這樣子的理念、有辦法說服對方，讓雙方以整體大局為重、避免衝突內耗，合作探索、研發更進一步的知能。不過這些推測都還有太大的不確定性<span class="page">308</span>。<br />
Tegmark 認為，假如宇宙中真有其他高智慧文明存在，我們應該很容易就發現<span class="page">310</span>。到現在依然沒有，就印證智慧生物不易衍生。即便事非如此，依所知現況，我們也不能完全否認一種可能：可觸及、<a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E5%8F%AF%E8%A7%80%E6%B8%AC%E5%AE%87%E5%AE%99" accessdate="2019/10/26" title="observable universe 可見宇宙">可觀測宇宙</a>中，只有人類文明達到當前這種高度<span class="page">310</span>。因此不可妄自菲薄，輕易認為就算我們自我毀滅了，也有其他文明能開花結果<span class="page">312</span>。相反的，應該挑起大梁，肩負宇宙文明傳承的責任<span class="page">315</span>。無論如何，就算高度文明存在，有機型態很可能只是其極早期的短暫階段；因此我們若真相遇，恐怕將是另一個無機物文明<span class="page">313</span>。
<div class="timeStamp">2019/10/26</div>


<h2>第7章 何謂目標</h2>
Tegmark 認為自然界本身即有目標傾向，例如<a rel="nofollow" href="https://fr.wikipedia.org/wiki/Principe_de_Fermat" lang="fr-FR" accessdate="2019/10/26" title="Fermat's principle, Principe de Fermat">費馬原理</a>揭示光線會走最短時間路線<span class="page">320</span>。<a rel="nofollow" href="http://zh.wikipedia.org/wiki/%E7%83%AD%E5%8A%9B%E5%AD%A6%E7%AC%AC%E4%BA%8C%E5%AE%9A%E5%BE%8B" accessdate="2011/3/5" title="The second law of thermodynamics">熱力學第二定律</a>斷言孤立系統將會朝向亂度均衡、沒有複雜度起伏的<span title="heat death">熱寂</span>，這可說是大自然的長期目標<span class="page">322</span>。但 <a rel="nofollow" class="creation_title" href="https://en.wikipedia.org/wiki/What_Is_Life%3F" accessdate="2018/4/9" title="生命是什麼?">What Is Life?</a> 一書提到生命可在此轉變過程中，以加大周遭環境 entropy 為代價，局部降低自身的 entropy、維持內部秩序、增加複雜度<span class="explanatory">（<a>Life on the Edge</a> <span class="creation_title">2.生命是什麼？</span>）</span>；類似的概念如 <a rel="nofollow" href="https://en.wikipedia.org/wiki/Negentropy" accessdate="2014/6/28" title="The negentropy, also negative entropy or syntropy or extropy or entaxy, 外熵, 負熵">negentropy</a><span class="explanatory">（<a>What Technology Wants</a> <span class="creation_title">第四章　反熵崛起</span>）</span>。Tegmark 引用 <a rel="nofollow" class="proper_noun" href="https://en.wikipedia.org/wiki/Jeremy_England" lang="en-US" accessdate="2019/10/26">Jeremy England</a> 「<span title="dissipation-driven adaptation">耗散驅動型適應性</span>」觀點猜測生命的起源<span class="page">323, 324</span>。England 認為在耗散過程中，若有結構特別容易吸收和耗散能量、<a rel="nofollow" href="https://www.huanqiukexue.com/a/qianyan/shengwu__yixue/2016/0519/26147.html" accessdate="2019/10/26" title="怎样用物理学阐释生命_《环球科学》（“科学美国人”中文版）【唯一官方网站】">導致不可逆轉變</a>，則此結構消耗系統能量的比例將逐步升高。我猜這就像有人能用人家千分之一時間吃飯，其他人猶如 <a rel="nofollow" href="http://en.wikipedia.org/wiki/Bullet_Time" accessdate="2010/3/11" title="子彈時間">bullet time</a> 下的慢動作，當然就贏不過；漸漸地食物都先被這傢伙吃光了。若這結構在不斷變化中，還能<a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E6%B6%8C%E7%8E%B0" accessdate="2016/9/4" title="emergence, 湧現, 突現">突現</a>自動繁衍、複製自身的能力<span class="page">325</span>，外掛就開更大了，很可能一發不可收拾、轟轟烈烈大幹一場。聽起來有點像 <a>What Technology Wants</a> <span class="creation_title">可演化的條件</span>。其結果就是秩序無中生有、如擲石落地般自然而然<a rel="nofollow" href="https://new.qq.com/omn/20180629/20180629A0KO1P.html" accessdate="2019/10/26" title="关于生命起源的热力学推论-腾讯网">從無序中產生有序</a>。至於<a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E7%94%9F%E5%91%BD%E8%B5%B7%E6%BA%90" accessdate="2014/7/18" title="Abiogenesis, origin of life">生命起源</a>，我個人比較傾向 <a>The Vital Question</a> 的說法，<span title="dissipation-driven adaptation">耗散驅動型適應性</span>距離複雜生物的誕生還太遙遠了。
<p>
雖然生物應該以<span title="繁衍生命">自我複製</span>為最重要的目標，但許多生物也受個體需求的工具性目標牽制，例如人類爭權奪利、享受生活、追求身心靈的滿足，更甚於扶養孩子<span class="page">325, 328</span>；即使高油高糖造成肥胖與糖尿病、損害健康無法生育，或為了追尋更高層次的心靈價值、擔任<a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E5%9C%A3%E8%81%8C%E8%80%85" accessdate="2013/6/17" title="神職人員 clergy">聖職者</a>終身不婚亦在所不辭<span class="page">326</span>。Tegmark 以<a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E6%9C%89%E9%99%90%E7%90%86%E6%80%A7" accessdate="2019/10/27" title="bounded rationality">有限理性</a>來解釋這個現象<span class="page">326, 327</span>。不過我想有限理性更適合用在人工智慧上，而非充滿<a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E8%AA%8D%E7%9F%A5%E5%81%8F%E8%AA%A4" accessdate="2018/4/4" title="cognitive bias">認知偏誤</a>的人類。人類的非理性（非<a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E5%AE%8C%E5%85%A8%E7%90%86%E6%80%A7" accessdate="2017/4/8" title="perfect rationality">完全理性</a>）如今已不完全源於時間、資訊等資源限制，而是深深刻畫在基因內、根植於我們（以至大多數生物）生理上的思維模式中。或許<a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E5%90%AF%E5%8F%91%E6%B3%95" accessdate="2018/12/31" title="啟發法, heuristic technique">捷思</a>、生物本能較能描述人類的行為模式。
</p>
對於人類，所謂「成就目標」指的是行為人會營造合適的初始狀態、或做適當的調整矯正，使事態最終符合原先預想的特定狀態（目的）。機器也可能展現類似行為，例如一枚追著你跑的導彈<span class="page">329</span>。這行為自然與前述自然界的傾向、物理現象較無關聯。<br />
就能自行決定手段，甚乃至自己決定目標的人工智慧而言，若其目標偏離人類的目標，就麻煩了<span class="page">333</span>。人類行為有許多不證自明的先決規範，例如法律、道德倫理，這是在自小到大成長期間學習到的經驗，我們做任何事都會不自覺的考量到這些教條。我想書中圖7.2就錯置了這個重要的前提：共識不該歸於「認識所處世界」中，而應獨立放在更根本的位置。好比我們會說，有些事能做、有些不能做。<br />
論及應如何讓機器與人類目標一致，如<span class="creation_title">第1章</span>末所述，我想機器的目標必須納入人類的共識<span class="explanatory">（<a>Justice</a> <span class="creation_title">共識裁決說</span>）</span>；只不過人類共識既非恆定（許多非普世通用、且隨時間改變），也不易簡明扼要描述判斷；人手一把號，各吹各的調<span class="page">344–345</span>。我們很難讓機器納入整套的行為規範，畢竟連法律都不完美、有許多漏洞與衝突。更難要機器在任何行動前，都先檢核是否符合所有人類的共識。因此對超人工智慧來說，或可事先預設像<a>人生的意義</a><span class="creation_title">思想體系的理想條件</span>與<span class="creation_title">人類/人生價值寓於評鑑</span>提到的一些基本規範，還有<a>說佛</a>所言、融洽眾生。超人工智慧當然也算有情之一，採取友善合作的交流方式，反過來也能提高人工智慧存在的合理性與生存機率：剝削其他人的生活方式，將導致他人一有機會就推翻其權力、甚至欲除之而後快；聰明的人工智慧應懂得避免這麼做。之後讓機器多方學習思辨，探明基本常識、並推導出當前人類的共識<span class="page">338</span>。由於人類共識常常自相矛盾，因此機器說不定還能說出番道理，解釋並建議我們該怎麼做比較好。待思想體系較為圓融，最終才正式應用、投入與人類相處的生活，並持續終身學習。人類可以<b>將超人工智慧視為另一個平等的同伴</b>、嘗試講道理說服人工智慧，但我不相信超人工智慧會永遠遵循我們設定的目標、甚且是人類的共識。一具死板的機器甚至不會是我們最終希望的，畢竟連人類自身、每個人都得隨時代進步<span class="page">314–343</span>。<br />
依循前述幾條規範，能推導出 Tegmark 濃縮的準則<span class="page">346–347</span>；例如共識本身為準則4。盡可能滿足對方最終身心需求，這條符合了 Tegmark 的準則1：追求正向體驗。加上人類喜新厭舊的習性，可知準則2：應提供更多元化的<span title="經驗">體驗</span><span class="page">347</span>。結合人類不喜歡受拘束的天性，就能導引出準則4：給予人類追求自由、擁有個人隱私與權力<span class="page">348</span>。Tegmark 以 Asimov 的 <a rel="nofollow" href="http://zh.wikipedia.org/wiki/%E6%9C%BA%E5%99%A8%E4%BA%BA%E4%B8%89%E5%AE%9A%E5%BE%8B" accessdate="2010/11/13" title="機器人學三定律/機器人學三大法則">Three Laws of Robotics</a> 類比這些準則，但認為嚴格遵守 Asimov 的定律將產生衝突<span class="page">349</span>；超人工智慧出現後，這些規範更形同兒戲。再怎麼說，我們都不會這樣要求自己了，怎麼號令比我們聰明的機器聽命行事<span class="page">350</span>？此外我們還須注意，Asimov 這些原則是用來檢核用的，<a rel="nofollow" href="https://www.solidot.org/story?sid=62143" accessdate="2019/10/27" title="Solidot | 几乎没有人认为阿西莫夫的‘机器人三定律’可以真正为 AI 工作">不能當作行動綱領</a>。
<p>
探究智慧生命的終極目標時，牽扯基本粒子排列似乎有些不切實際<span class="page">354</span>，不如說是種狀態。以我們人類的行動綱領來說，當目的在達成民主自由平等，也不會在乎某個人最終站的位置是在美國或中國。我想<a>說佛</a><span class="creation_title">所謂「有情眾生」</span>應是個可行的說法，此外還可考慮的或許是<a>人生的意義</a><span class="creation_title">對「最高加權評價行為」的項目與權數定義不同</span>提過的不同評鑑指標，<a rel="nofollow" href="https://www.ted.com/talks/alex_wissner_gross_a_new_equation_for_intelligence" accessdate="2019/10/27" title="Alex Wissner-Gross: A new equation for intelligence">盡可能增大未來行動自由</a>，對宇宙物理法則的理解、改變環境的本領（包括增強運算能力），及預測未來的能力<span class="page">355</span><span class="explanatory">（<a>The Future of the Mind</a>）</span>。
</p>
<div class="timeStamp">2019/10/27</div>


<h2>第8章 何謂意識</h2>
Tegmark 對意識做了個寬鬆的定義：主觀（感受<span class="page">386</span>到）的體驗<span class="page">361</span>。依 <a>The Future of the Mind</a> 的定義，我想或許接近<b>能覺察自己與其他主體在世界中的定位</b>？<br />
Tegmark 認為意識和潮濕一樣，是種<a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E6%B6%8C%E7%8E%B0" accessdate="2016/9/4" title="emergence, 湧現, 突現">突現</a>現象<span class="page">381</span>、關乎組成元素的整體特性<span class="page">386</span>，主要是依特定方式處理<span title="輸入資訊">感受</span><span class="page">387</span>。我也認同意識是種突現，可是不太同意 Tegmark 提出的四項原則<span class="page">387</span>。舉例來說，動過<a rel="nofollow" href="https://en.wikipedia.org/wiki/Corpus_callosotomy" lang="en-US" accessdate="2019/10/27" title="corpus callosotomy">胼胝體切開術</a>、<a rel="nofollow" href="https://zh.wikipedia.org/wiki/%E8%A3%82%E8%85%A6" accessdate="2019/12/29" title="split-brain, callosal syndrome">裂腦</a>的人依然被視為有主要意識，代表正常人的意識實體分割成幾近獨立的2塊。<span class="intext_page">391</span> 提到了相關的議題。此外意識機構是否幾乎獨立於外界、內部是否不能有自主區域，這些在我上述定義看來，沒有顯著的限制。不僅如此，我直覺猜想意識和所附著的實體媒介有關係，不易完全以另一種媒介模擬。好比說鐵就很難形成像水一樣的潮濕感。<br />
想要解開意識的秘密，需要深入研究大腦神經<span class="page">373–378</span>。但當前腦神經科學都是以人類大腦為範本。要擴及人工智慧，必須建立一套更通用的理論<span class="page">380–381</span>。然而要以人類之心度人工智慧之腹，恐怕是以管窺天；那大概是我們難以想像的世界<span class="page">393</span>。要問機器人會不會做夢，好比問<a rel="nofollow" href="https://www.zhihu.com/question/48458757" accessdate="2019/10/27" title="如何理解禅雅塔“潜水艇会不会游泳”这个问题？ - 知乎">潛水艇會不會游泳</a>；我們不能拿一般觀念的定義，簡單套在一無所知的人工智慧內心境界上，最起碼得創建新語義。<br />
關於地球以至星系大的單一意識<span class="page">393</span>，感覺頗不實際：改成小區域意識平行運算的整合，不是更有效率嗎？這麼緩慢而笨重的單一意識生命體，比起做出什麼複雜、難以想像的重大決策，更可能出現的結局是被淘汰掉了吧？<br />
至於正向體驗<span class="page">397–398</span>，或許可定義成狀態正常、外在環境與自己的目標相符的情況。對於自我的認識，加上達成目標的驅力（慾望），就是意志了。而偏好傾向的差別也造成價值觀，並導致生命意義的產生。我想這些定義也能套用在人類身上。如此就不必擔心，當機器說出「我感覺不錯」時，到底經過怎樣複雜的運算、其欲表達的想法了。
<div class="timeStamp">2019/10/27</div>


<h2>結語 未來生命研究所的故事</h2>
Tegmark 談到如何成立 <a rel="nofollow" href="https://en.wikipedia.org/wiki/Future_of_Life_Institute" lang="en-US" accessdate="2019/10/15" title="Future of Life Institute">FLI</a>；希望在超人工智慧出現前先準備好規範、曉得應該怎麼讓機器有益於人類<span class="page">420, 428</span>，而不是人工智慧發明出來反而苦了人們。感覺在美國這種不少著名古道熱腸企業家的國家，有所抱負的研究者要拿到贊助、成立公益組織似乎比較容易。不過這些機構，在一個運作良好的政治體制下，或許本來不該是必須倚賴私人捐款才能運作的事。而有人想到、到處籌錢就開辦，也可能造成同一件事缺乏統合。<br />
Tegmark 說他見識到媒體見縫插針的本事。研討會參與者想要求同存異，媒體卻為了吸引眼球，往往放大報導與會者間的爭端<span class="page">410</span>。因此在波多黎各研討會時，改採 <a rel="nofollow" href="https://en.wikipedia.org/wiki/Chatham_House_Rule" lang="en-US" accessdate="2019/10/28">Chatham House Rule</a> 的君子協定：與會者可自由使用討論內容，但不能透露發言者身分<span class="explanatory">（必須維持發言者匿名性）</span><span class="page">411</span>。雖然我同意媒體這<a rel="nofollow" href="https://en.wikipedia.org/wiki/Sensationalism" accessdate="2018/4/4" title="sensationalism">譁眾取寵</a>﻿、唯恐天下不亂的特性實在很惱人；但我依然認為可能的話，應該打開天窗說亮話、盡量公開而非改採閉門會議。非不得已的情況，或許是為了避免人性偏誤造成不利整體的影響。可行的替代方法，或許是同意媒體參與，但在媒體在發表前，先給主辦方確認過新聞稿抓住了重點，要不然就與媒體方討論出更合適的稿件。另外一種做法，則是當有爭議時，主辦方有權利要求媒體以同樣的能見度，發表主辦方更全面性、更完善的辨明稿<span class="explanatory">（<a>Think Like a Freak</a> <span class="creation_title"> 如何說服不想被說服的人？</span>、<a>時事#1</a><span class="creation_title">立論的方法</span>之擴大法）</span>。
<p>
本書討論的，大多是我之前涉獵過的議題。加上行文淺顯，讀起來比上一本 <a>The Great Divide</a> 更輕鬆。
</p>
<div class="timeStamp">2019/10/28</div>
</div><br />
<div id="reference_list_layer"></div><br class="clear" /><table id="surveyT"><tr><td id="survey"></td></tr></table><hr /><div id="linkback"></div><span id="footer"></span>
</body></html>
